% Paper 1
\subsection[Presentation of Barredo Arrieta et al. (2020)]{Presentation of \textcite{Barredo_2020}}
The first paper, \citetitle{Barredo_2020} by \textcite{Barredo_2020}, is a conceptual paper explaining the field of explainable artificial intelligence (XAI). The paper starts out by clarifying concepts and definitions for XAI. It introduces the concept of \textit{audience} to XAI, changing the definition of explainable AI to "Given an audience, an explainable Artificial Intelligence is one that produces details or reasons to make its functioning clear or easy to understand" \parencite[p.85]{Barredo_2020}.

The authors goes on to discuss current methods for making artificial intelligence systems more explainable, before it performs a thorough literature review in the field of XAI, splitting the current research in two parts -- one focused on general explanation methods, the other focused solely on methods aimed at explaining deep learning systems. With the review fresh in memory, the paper discusses challenges and future research opportunities within the field of XAI, mentioning cases such as interpretability possibly lowering performance, the lack of consensus regarding the definition of explainability, and the current lack of methods for explaining deep learning models.

The paper goes on to introduce the concept of responsible artificial intelligence, by building upon the research done on XAI, adding fairness, accountability and privacy to the previously used definition. The paper rounds out by welcoming reflections on XAI in sensitive scenarios, finishing by discussing how XAI methods can work in privacy- and security-focused systems.



\subsection[Evaluation of Barredo Arrieta et al. (2020)]{Evaluation of \textcite{Barredo_2020}}
TODO